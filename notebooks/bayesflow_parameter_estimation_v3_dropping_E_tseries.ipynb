{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "# Data\n",
    "from seird.model import data_generator, version_data_model\n",
    "\n",
    "# Model\n",
    "from bayesflow.bayesflow_model import BayesFlow\n",
    "from bayesflow.networks import HeteroskedasticModel, SequenceNet\n",
    "from bayesflow.losses import heteroskedastic_loss, maximum_likelihood_loss\n",
    "from bayesflow.trainer import train_step\n",
    "\n",
    "# Misc\n",
    "from utils.misc import true_vs_estimated\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network hyperparameters\n",
    "inv_meta = {\n",
    "    'n_units': [64, 64, 64],\n",
    "    'activation': 'elu',\n",
    "    'w_decay': 0.0,\n",
    "    'initializer': 'glorot_uniform'\n",
    "}\n",
    "n_inv_blocks = 5\n",
    "\n",
    "# Optional if using the predefined summary nets\n",
    "summary_meta = {\n",
    "    'lstm_units': [192, 192, 192],\n",
    "    'activation': 'elu',\n",
    "    'w_decay': 0.0,\n",
    "    'initializer': 'glorot_uniform'\n",
    "}\n",
    "\n",
    "\n",
    "# Forward model hyperparameters\n",
    "parameter_names = [r'$\\beta$', r'$\\sigma$', r'$\\gamma$', r'$\\mu_I$']\n",
    "theta_dim = len(parameter_names)\n",
    "n_test = 500\n",
    "\n",
    "\n",
    "# Training and optimizer hyperparameters\n",
    "ckpt_file = \"bayesflow_parameter_estimation_v3_dropping_E_tseries\"\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "iterations_per_epoch = 1000\n",
    "n_samples_posterior = 2000\n",
    "\n",
    "starter_learning_rate = 0.001\n",
    "global_step = tf.Variable(0, dtype=tf.int32)\n",
    "decay_steps = 1000\n",
    "decay_rate = .95\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(starter_learning_rate, decay_steps, decay_rate)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_test = data_generator(n_test)\n",
    "\n",
    "# Preprocessing untrained data\n",
    "X_test = np.array(data_test['X'])\n",
    "params_test = np.array(data_test['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_test))\n",
    "print(X_test.shape)\n",
    "print(type(params_test))\n",
    "print(params_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks for numerical stability\n",
    "assert(np.sum(X_test == np.inf) == 0)\n",
    "assert(np.sum(X_test == -np.inf) == 0)\n",
    "assert(np.sum(X_test == np.nan) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(params_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop E compartment tseries\n",
    "X_test = np.delete(X_test, 1, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(params_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "summary_net = SequenceNet()\n",
    "model = BayesFlow(inv_meta, n_inv_blocks, theta_dim, summary_net=summary_net, permute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vs_estimated(model, X_test, params_test, n_samples_posterior, parameter_names, figsize=(12, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.Checkpoint(step=global_step, optimizer=optimizer, net=model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, './checkpoints/{}'.format(ckpt_file), max_to_keep=3)\n",
    "checkpoint.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "for ep in range(1, epochs + 1):\n",
    "    with tqdm(total=iterations_per_epoch, desc='Training epoch {}'.format(ep)) as p_bar:\n",
    "        losses = train_step(model=model, \n",
    "                            optimizer=optimizer,\n",
    "                            loss_fn=maximum_likelihood_loss, \n",
    "                            iterations=iterations_per_epoch,\n",
    "                            batch_size=batch_size,\n",
    "                            p_bar=p_bar,\n",
    "                            global_step=global_step) \n",
    "\n",
    "        # Manage checkpoint\n",
    "        manager.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from trained model\n",
    "params_samples = model.sample(X_test, n_samples_posterior, to_numpy=True)\n",
    "\n",
    "# For each tseries compute mean of sampled posteriors\n",
    "# For each tseries, n_samples_posterior set of parameters were samples\n",
    "params_samples_mean = params_samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling sanity checks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
